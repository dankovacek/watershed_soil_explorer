{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import cartopy\n",
    "import fiona\n",
    "\n",
    "from xml.dom import minidom\n",
    "import zipfile\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "from shapely import geometry\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "from geoviews import opts, tile_sources as gvts\n",
    "\n",
    "from bokeh.plotting import figure, output_file, show\n",
    "from bokeh.io import output_notebook\n",
    "from bokeh.tile_providers import Vendors, get_provider\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import Band, ColumnDataSource\n",
    "from bokeh.models import Label, LabelSet, Range1d\n",
    "from bokeh.palettes import Plasma4, Plasma6, Plasma10\n",
    "from bokeh.layouts import column, gridplot\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension('bokeh')\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHANNON - **S**oil c**H**aracterization c**AN**ada basi**N** p**O**lygo**N**s\n",
    "\n",
    "18 Feb. 2021 - Dan Kovacek\n",
    "\n",
    "Python library requirements are above, most are straightforward and can be installed by your package manager (`pip` or `conda`), however you may have to install pygeos to your system and restart the kernel at the polygon intersection step.  This notebook was created and tested on Ubuntu 18 only, so YMMV!\n",
    "\n",
    "## Purpose \n",
    "\n",
    "Retrieve data from [Gridded Soil Landscapes of Canada](https://sis.agr.gc.ca/nsdb/ca/cac003/cac003.20110308.v3.2/ca_all_slc_v3r2.zip) (GSLC), and use basin polygons to characterize soil information specific to the watersheds of interest.\n",
    "\n",
    "## Gridded Soil Landscapes of Canada (GSLC) Data\n",
    "\n",
    "While the [specifications](https://www.agr.gc.ca/atlas/supportdocument_documentdesupport/soilLandscapesOfCanada90mGrid/en/ISO_19131_Gridded_SLC_Data_Product_Specification.pdf) of the GSLC describe the data as 'gridded', it looks as though each row of the **GSLC** data (`data/ca_all_slc_v3r2/`) defines a polygon associated with a unique set of characteristics.  The `POLY_ID` column is the unique identifier for an area with a defined set of soil characteristics.  The large number of files makes it difficult to grasp the information contents of the GSLC in its entirety, but it seems that the POLY_ID is the common (or primary) key connecting the different information sources.  Further information about how the GSLC data is formatted is [here](https://sis.agr.gc.ca/cansis/nsdb/slc/v3.2/change.html), i.e. '*SLC map polygons are described by a set of soil components, defined by soil codes that are unique to each province.*'  Soil names and soil layers can be found [here](https://sis.agr.gc.ca/cansis/nsdb/soil/v2/download.html).  A visual mapping of the SLC data model is [here](https://sis.agr.gc.ca/cansis/nsdb/slc/v3.2/model.html).\n",
    "\n",
    "## How others have summarized the information\n",
    "\n",
    "A presentation of slides describing development of the SLC is [here](https://www.nrcs.usda.gov/Internet/FSE_DOCUMENTS/nrcs142p2_051155.pdf).  Slide 3 shows what the polygons actually look like.  Slide 7 of [this presentation](https://www.nrcs.usda.gov/Internet/FSE_DOCUMENTS/nrcs142p2_052032.pdf) talks about the SLC **component table.**\n",
    "\n",
    "## Spatial Information\n",
    "\n",
    "A tricky step in combining disparate data sources is managing coordinate reference systems (CRS).  Different data sources often use different coordinate reference systems, and the GSLC information comes in many different file types that are handled by different Python libraries.  Spatial data uses some coordinate reference system (CRS) and there are [many, many, many](https://spatialreference.org/) of these because the earth ~~is flat~~ is not perfectly spherical, so the deviations from a sphere cause inaccuracy if you try using one projection over too large an area.    \n",
    "\n",
    "In general, for plotting shapes and points on top of some kind of base mapping, we need to use a geographic [web mercator CRS](https://www.esri.com/news/arcuser/0312/national-geographic-basemap.html).  In Google maps, as well as many base maps used in Python libraries, the base map coordinates are expressed in decimal degrees (EPSG 4326), so any geometries must be converted to the *geometric CRS* of the base map for plotting.  The CRS can be converted to a *projected CRS* for other operations, such as calculating distance or area (this isn't strictly necessary, but you need to deal with geometric decimal conversions if you don't).\n",
    "\n",
    "Python libraries use an EPSG code (EPSG is the public registry of geodetic datums) to convert between datums/projections.  The SLC polygons are in the *Canada Albers Equal Area Conic* projection of the NAD83 datum.  The [EPSG for the SLC is 4269](https://epsg.io/4269).  For overlaying geographic information on 'web mercator' tiles, the [EPSG code used here is 4326](https://epsg.io/4326) (the common WGS84 used in GPS).  For spatial calculations, use NAD83 / BC Albers (EPSG 3005)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "\n",
    "1. Import the WSC watershed basin polygons\n",
    "    * download the National hydrometric network basin polygons, and save the zip file under `data/`. The zip archive doesn't need to be extracted.\n",
    "2. Import custom polygons made in Google Earth and exported \n",
    "    * save these under `data/google_earth_polygons`\n",
    "3. Verify coordinate systems and merge the polygons of interest into one geodataframe.\n",
    "4. Calculate catchment parameters of interest\n",
    "    * area and perimeter (Gravelius compactness can then be calculated as the basin perimeter divided by the perimeter of a circle with area equal to the basin area:\n",
    "        $$K_G = \\frac{P}{2\\sqrt{\\pi A}}$$\n",
    "4. Import GSLC polygons.\n",
    "5. Perform an intersection of the basin polygons with the soil polygons.\n",
    "6. Use the output of the intersection to determine the basin composition by polygon ID.\n",
    "7. Cross reference polygon ID against other data sources to find soil characteristics of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import WSC Watershed Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my file is located elsewhere, so delete the line below\n",
    "WSC_basin_polygons_path = os.path.abspath(os.path.join(os.getcwd(), '../../hydat_db/'))\n",
    "# if you followed the instructions in the introduction above, \n",
    "# you should have saved the file under data/, so delete the line above\n",
    "# and use the one below instead\n",
    "# WSC_basin_polygons_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all wsc_catchment data into its own dataframe\n",
    "gdb_path = os.path.join(WSC_basin_polygons_path, 'WSC_Basins.gdb.zip')\n",
    "all_layers = fiona.listlayers(gdb_path)\n",
    "all_layer_names = [e.split('_')[1].split('_')[0] for e in all_layers]\n",
    "\n",
    "# replace this with some call to define the sites of interest\n",
    "all_sites = ['08MH147', '08ME002'] # 08MH147 is Stave River, 08ME002 is Lillooet River\n",
    "filtered_layers = list(set(all_sites).intersection(all_layer_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polygon(stn):\n",
    "    \"\"\"\n",
    "    Retrieve a watershed basin polygon based on the WSC Station ID.\n",
    "    \"\"\"\n",
    "    gdb_path = os.path.join(WSC_basin_polygons_path, 'WSC_Basins.gdb.zip')\n",
    "    data = gpd.read_file(gdb_path, driver='FileGDB', layer='EC_{}_1'.format(stn))\n",
    "    # view the original CRS\n",
    "    print(data.crs)\n",
    "    # convert to WGS 84 / Pseudo-Mercator -- Spherical Mercator, Google Maps, OpenStreetMap, Bing, ArcGIS, ESRI\n",
    "    # NOTE: for distance calculations, revert to original CRS (EPSG 4269) to get correct values\n",
    "    data = data.to_crs(4269)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_array = [get_polygon(site) for site in all_sites]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the basin polygons in a geopandas geodataframe\n",
    "all_basin_polygons = gpd.GeoDataFrame(pd.concat(shape_array, ignore_index=True))\n",
    "all_basin_polygons\n",
    "all_basin_polygons.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import custom polygons from Google Earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a test polygon created in Google Earth\n",
    "gpd.io.file.fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "\n",
    "def kmz_to_kml(fname):\n",
    "    \"\"\"\n",
    "    Save kmz to kml.\n",
    "    From: https://community.esri.com/t5/python-snippets-documents/convert-kmz-to-kml/ta-p/914947\n",
    "    \"\"\"\n",
    "    zf = zipfile.ZipFile(fname, 'r')\n",
    "    for fn in zf.namelist():\n",
    "        if fn.endswith('.kml'):\n",
    "            content = zf.read(fn)\n",
    "            xmldoc = minidom.parseString(content)\n",
    "            out_name = (fname.replace(\".kmz\",\".kml\")).replace(\"\\\\\",\"/\")\n",
    "            out = open(out_name,'w')\n",
    "            out.writelines(xmldoc.toxml())\n",
    "            out.close()\n",
    "        else:\n",
    "            print(\"no kml file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_polygon_fp = 'data/google_earth_polygons/'\n",
    "# custom_files = [e for e in os.listdir(custom_polygon_fp) if e.split('.')[-1] in ['kmz', 'kml']]\n",
    "kmz_files = [e for e in os.listdir(custom_polygon_fp) if e.split('.')[-1] == 'kmz']\n",
    "for k in kmz_files:\n",
    "    kmz_to_kml(custom_polygon_fp + k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the WSC basin polygons and custom GE-derived polygons into one GeoDataFrame\n",
    "\n",
    "For geometric calculations, the [BC Environment Standard Projection is BC Albers Equal Area Conic](https://ibis.geog.ubc.ca/~brian/Course.Notes/bceprojection.html) (EPSG:3005).  See also [spatialreference.org](https://spatialreference.org/ref/epsg/3005/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_custom_polygons(custom_files):\n",
    "    i = len(all_basin_polygons)\n",
    "    for custom_file in custom_files:\n",
    "        name = custom_file.split('.')[0].split('_')[-1]\n",
    "        custom_shape = gpd.read_file(f'data/google_earth_polygons/{custom_file}', driver='kml')\n",
    "        print(f'Original CRS of {name} polygon is {custom_shape.crs}')\n",
    "        print(custom_shape.geometry)\n",
    "        # kml files look like they are in 4326 by default (decimal degrees), \n",
    "        # though this could just be the Google Earth settings.\n",
    "\n",
    "        # 3005\n",
    "        custom_shape = custom_shape.to_crs(3005)\n",
    "        custom_area = custom_shape['geometry'].area[0]/ 1E6\n",
    "        custom_length = custom_shape['geometry'].length[0]/ 1E3\n",
    "        print(f'Updated CRS of {name} polygon is {custom_shape.crs}')\n",
    "        print(f'{name} basin area is {custom_area:.1f} km^2')\n",
    "        print(f'{name} basin perimeter is {custom_length:.1f} km^2')\n",
    "        custom_shape = custom_shape.to_crs(4269)\n",
    "        print(f'Updated CRS of {name} polygon is {custom_shape.crs}')\n",
    "        print('')\n",
    "        # add our custom google earth kml\n",
    "        print(all_basin_polygons.crs)\n",
    "        all_basin_polygons.loc[i, 'Station'] = name\n",
    "        all_basin_polygons.loc[i, 'StationNam'] = name\n",
    "        all_basin_polygons.loc[i, 'Stn_UID'] = None\n",
    "        all_basin_polygons.loc[i, 'Shp_Area'] = custom_area\n",
    "        all_basin_polygons.loc[i, 'Shp_Perime'] = custom_length\n",
    "        all_basin_polygons.loc[i, 'Shape_Length'] = custom_length * 10**3\n",
    "        all_basin_polygons.loc[i, 'Shape_Area'] = custom_area * 10**6\n",
    "        all_basin_polygons.loc[i, 'geometry'] = custom_shape.geometry[0]\n",
    "        i += 1\n",
    "    return custom_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_kml_files = [e for e in os.listdir(custom_polygon_fp) if e.split('.')[-1] == 'kml']\n",
    "custom_shapes = import_custom_polygons(custom_kml_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In google earth, the Snowshoe Creek basin area is 307 $km^2$ and the perimeter is $76.7 km^2$.   ( < 1% difference in area calculations).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_basin_polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Basin Characteristics and Convert to plotting CRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basins_df = gpd.GeoDataFrame(all_basin_polygons['geometry'], crs='EPSG:4269')\n",
    "basins_df = basins_df.to_crs(3005)\n",
    "basins_df['station'] = all_basin_polygons['Station']\n",
    "basins_df['gravelius'] = all_basin_polygons['Shp_Perime'] / (2 * np.sqrt(np.pi * all_basin_polygons['Shp_Area']))\n",
    "basins_df['centroid'] = all_basin_polygons['geometry'].centroid\n",
    "print(basins_df.crs)\n",
    "print(basins_df.total_bounds)\n",
    "\n",
    "# convert back to 4326 for plotting against geo tiles\n",
    "basins_df = basins_df.to_crs(epsg=4269)\n",
    "print(basins_df.crs)\n",
    "print(basins_df.total_bounds)\n",
    "\n",
    "basins_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot basins, basin centroids, and map Gravelius coeff. to colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back to 4326 for plotting against geo tiles\n",
    "basin_centroids = gpd.GeoDataFrame({'geometry': basins_df['centroid'].copy()})\n",
    "basin_centroids = basin_centroids.to_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = gv.Points(basin_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv.Polygons(basins_df, vdims=['gravelius']).opts(colorbar=True, \n",
    "                                                 alpha=0.5,\n",
    "                                                 frame_height=400,\n",
    "                                                 color_index='gravelius',\n",
    "                                                 clabel='Gravelius',\n",
    "                                                data_aspect=True) * gvts.EsriNatGeo * centroids.opts(size=10, color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the GSLC Data\n",
    "\n",
    "[Download the GSLC dataset](https://www.agr.gc.ca/atlas/data_donnees/geo/soilLandscapesOfCanada90mGrid/tif/gridded_slc_90m.zip), and extract the zip archive in the `data/` folder, or change the `shape_path` string below to match the file path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridded SLC data product specification says EPSG: 3978 - NAD1983\n",
    "# but at import the data suggests 4269\n",
    "\n",
    "shape_path = 'data/ca_all_slc_v3r2/ca_all_slc_v3r2.shp'\n",
    "\n",
    "with fiona.open(shape_path, \"r\") as shapefile:\n",
    "    # note this is consistent with the data specification\n",
    "    print(shapefile.crs)\n",
    "    \n",
    "    areas = [s['properties']['AREA'] for s in shapefile]\n",
    "    perims = [s['properties']['PERIMETER'] for s in shapefile]\n",
    "    poly_IDs = [s['properties']['POLY_ID'] for s in shapefile]\n",
    "    eco_IDs = [s['properties']['ECO_ID'] for s in shapefile]\n",
    "\n",
    "    \n",
    "    geometries = [geometry.Polygon(s['geometry']['coordinates'][0]) for s in shapefile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first format the imported data into a regular pandas dataframe\n",
    "geo_dict = {'POLY_ID': poly_IDs,\n",
    "           'ECO_ID': eco_IDs,\n",
    "            'area': areas,\n",
    "            'perimeter': perims,\n",
    "           'geometry': geometries}\n",
    "geo_df = pd.DataFrame(geo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert the data to a geopandas geodataframe\n",
    "# and set the CRS for plotting\n",
    "gdf = gpd.GeoDataFrame(geo_df, crs='epsg:4269')\n",
    "print(gdf.crs)\n",
    "\n",
    "print(gdf.total_bounds)\n",
    "# gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the SL dataset and watershed dataset total bounds\n",
    "basins_df = basins_df.to_crs(4269)\n",
    "print(basins_df.total_bounds)\n",
    "print(f'basins_df crs = {basins_df.crs}')\n",
    "\n",
    "\n",
    "\n",
    "# gdf = gdf.to_crs(4269)\n",
    "print(gdf.total_bounds)\n",
    "print(f'SLC crs = {gdf.crs}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the Soil Lanscape Polygon Intersections with Basins\n",
    "\n",
    "The `gpd.overlay` function may give some issues.  The error I was getting suggested I needed rtree (which was installed) or pygeos (which made shapely stop working).  Some info [here](https://geopandas.org/install.html).  I uninstalled and reinstalled geopandas, then reinstalled pygeos, performed some ancient rite of mysticism and it just worked.\n",
    "\n",
    "The overlay function worked incredibly quickly to process the entire GSLC polygon set to find the overlapping zones.  \n",
    "\n",
    "## So satisfying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_intersection = gpd.overlay(gdf, basins_df, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that the area, perimeter, Gravelius, and centroid values are incorrect** because the data is in the geometric decimal degree format.  The dataframe crs has to be changed back to a mercator projection to get units in metres.\n",
    "\n",
    "In the printout below of the resulting table, the basins are split by the soil information polygons, so a pandas `groupby` operation will let you iterate over all the sub-polygons of each basin to get fractional areas, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the figure below, you can hover to get the POLY_ID.  Neat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv.Polygons(res_intersection, vdims=['POLY_ID']).opts(tools=['hover'],\n",
    "                                                cmap='Spectral',\n",
    "                                                alpha=0.8,\n",
    "                                                frame_width=250,\n",
    "                                                data_aspect=True) * gvts.EsriNatGeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_intersection['idx'] = res_intersection.index\n",
    "res_intersection.sort_values('POLY_ID', inplace=True)\n",
    "res_intersection = res_intersection.to_crs(3005)\n",
    "res_intersection['area'] = res_intersection['geometry'].area / 1E6\n",
    "res_intersection['perimeter'] = res_intersection['geometry'].length / 1E3\n",
    "res_intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP: address the issue with the polygon areas not being correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_table = pd.DataFrame(res_intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Incorporate additional soil information files\n",
    "\n",
    "* Harvey's area in GE is $6.7 km^2$\n",
    "* Magnesia's area in GE is $4.9 km^2$\n",
    "\n",
    "The differences between GE polygon areas and those calculated below are not constant multipliers.  They range between $1.5^2 \\rightarrow 2^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_table.groupby('station').sum()['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
